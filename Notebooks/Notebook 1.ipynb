{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abea2a45",
   "metadata": {},
   "source": [
    "# Volatility Surface Construction – Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44104712",
   "metadata": {},
   "source": [
    "### 1.1 Project Overview & Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ee47e",
   "metadata": {},
   "source": [
    "This project investigates the calibration of the implied volatility surface for the SPDR S&P 500 ETF Trust (SPY). The volatility surface is a fundamental object in quantitative finance, representing the market's expectation of future volatility across varying strike prices and times to maturity. A static, arbitrage-consistent implied volatility surface is essential for the consistent pricing of vanilla and exotic derivatives, as well as for risk management tasks such as hedging.\n",
    "\n",
    "The primary objective is to calibrate two industry-standard parametric models—Stochastic Volatility Inspired (SVI) and Stochastic Alpha, Beta, Rho (SABR)—to a single-day snapshot of market option prices. We aim to minimize the calibration error between model-implied volatilities and market-observed volatilities, subsequently analyzing the structural properties and fit quality of each model.\n",
    "\n",
    "**Asset Selection:**\n",
    "SPY is selected as the underlying asset due to its status as one of the most liquid equity derivatives globally. It provides a dense grid of strike prices and maturities, which is critical for ensuring stable parameter estimation and minimizing interpolation errors that occur in illiquid chains. The distinct equity skew observed in SPY options provides a robust testing ground for the skew-capture capabilities of SVI and SABR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66515e41",
   "metadata": {},
   "source": [
    "### 1.2 Computational Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f697764",
   "metadata": {},
   "source": [
    "The project workflow is divided into distinct stages, handled by specific modules in the `src/` directory and documented across sequential notebooks:\n",
    "\n",
    "1.  **Data Acquisition (Backend):** Raw option chains, spot prices, and yield curves are extracted via `src/data_loader.py`.\n",
    "2.  **Preprocessing & Filtering (Notebook 1):** Application of liquidity filters, moneyness bounds, and spread controls to isolate valid calibration data.\n",
    "3.  **Implied Volatility Extraction (Notebook 2):** Conversion of option premiums to implied volatilities using numerical inversion.\n",
    "4.  **Parametric Surface Modeling (Notebook 3 to 5):** Optimization of SVI and SABR parameters against the filtered volatility smile.\n",
    "5. **Research Conclusions (Notebook 6):** Visualizations and diagnostics to evaluate model comaprison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea095634",
   "metadata": {},
   "source": [
    "### 1.3 Data Sourcing & Modeling Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c672b56",
   "metadata": {},
   "source": [
    "Market data is sourced via the `yfinance` API. To ensure consistency in the calibration process, specific conventions and assumptions are applied prior to modeling.\n",
    "\n",
    "**1. Option Pricing Convention**\n",
    "The calibration target is the **Mid-Price**, calculated as $0.5 \\times (Bid + Ask)$. This mitigates the bid-ask bounce and provides a representative fair value for the contract.\n",
    "\n",
    "**2. Interest Rates & Dividends**\n",
    "The risk-free rate ($r$) is approximated as a flat term structure based on the 1-year Treasury yield. While the yield curve is generally upward sloping, a flat rate is a standard simplification for single-snapshot surface calibration where the focus is on the smile shape rather than term-structure arbitrage. The dividend yield ($q$) is extracted from the underlying asset's trailing yield.\n",
    "\n",
    "**3. European Approximation**\n",
    "SPY options are American-style (exercisable at any time). However, for the purpose of implied volatility surface construction, they are modeled as European options. This approximation is standard in equity volatility modeling, justified by the limited impact of early exercise premium on short-to-medium dated options, particularly outside deep in-the-money regions.\n",
    "\n",
    "**Note:** To ensure abundant observations, the data was preventively fetched 15 min before US market close."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39163c4f",
   "metadata": {},
   "source": [
    "### 1.4 Feature Engineering & Filtering Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6b3be",
   "metadata": {},
   "source": [
    "The raw dataset undergoes rigorous filtering to remove microstructure noise and arbitrage-violating quotes. This logic is implemented in the data processing pipeline.\n",
    "\n",
    "**Derived Metrics**\n",
    "\n",
    "The **Forward Price** ($F$) is calculated as:\n",
    "$$ F = S_0 e^{(r-q)T} $$\n",
    "\n",
    "**Log-Moneyness** ($k$) serves as the standardized spatial coordinate for the volatility smile:\n",
    "$$ k = \\ln\\left(\\frac{K}{F}\\right) $$\n",
    "\n",
    "**Total Variance** ($w$) is the calibration target for the SVI model:\n",
    "$$ w = \\sigma_{imp}^2 T $$\n",
    "\n",
    "**Filtering Criteria**\n",
    "\n",
    "To ensure the integrity of the calibration dataset, the following filters are applied:\n",
    "\n",
    "* **Spread Quality:** Contracts with a relative spread $\\frac{Ask - Bid}{Mid} > 20\\%$ are discarded to avoid unreliable mid-prices.\n",
    "* **Maturity Bounds:** $7 \\text{ days} \\leq T \\leq 2 \\text{ years}$. Very short maturities are excluded due to microstructure noise and gamma risk; very long maturities are excluded due to illiquidity.\n",
    "* **Liquidity:** $Volume > 1$ and $OpenInterest > 10$ to remove \"ghost\" quotes.\n",
    "* **Moneyness:** $|k| \\leq 0.30$. Calibration is restricted to the liquid strike range (approx. $\\pm 30\\%$ from spot) where the models are most stable.\n",
    "* **Call/Put Consistency:** Out-of-the-money (OTM) options are prioritized for implied volatility extraction (OTM Puts for $K < F$, OTM Calls for $K > F$) to utilize the most liquid instruments.\n",
    "* **IV Bounds:** $1\\% \\leq IV \\leq 300\\%$ to filter numerical inversion failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3dfad5",
   "metadata": {},
   "source": [
    "### 1.5 Statement of Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891afa91",
   "metadata": {},
   "source": [
    "While the methodology adheres to standard industry practices, the following limitations apply:\n",
    "\n",
    "1.  **American Premium:** Treating SPY options as European ignores the early exercise premium, potentially overestimating implied volatility for deep ITM puts.\n",
    "2.  **Flat Term Structure:** The use of a constant $r$ ignores the slope of the yield curve, which may introduce minor biases in the forward price calculation for longer-dated maturities.\n",
    "3.  **Snapshot Validity:** This analysis is a static calibration to a single point in time. It does not account for the temporal dynamics of the volatility surface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32274d4",
   "metadata": {},
   "source": [
    "### 1.6 Conclusion & Handoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22833d82",
   "metadata": {},
   "source": [
    "The data processing pipeline results in a cleaned, structured CSV file containing the necessary inputs for model calibration: Strike, Expiration, Time to Maturity ($T$), Log-Moneyness ($k$), and Market Implied Volatility ($\\sigma_{imp}$).\n",
    "\n",
    "The cleaned dataset is stored in `src/options_data.csv`. **Notebook 2** will ingest this file to build the necessary numerical foundations before calibrating the SVI and SABR models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define path to the processed dataset generated by the backend pipeline\n",
    "csv_path = Path.cwd().parent / \"src\" / \"options_data.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the processed data to verify structure for the next notebook\n",
    "    final_df = pd.read_csv(csv_path)\n",
    "    print(\"Processed Data Schema:\")\n",
    "    final_df.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Processed file not found at: {csv_path}. Please run src/data_loader.py first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
